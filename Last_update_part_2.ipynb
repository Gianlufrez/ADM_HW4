{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e465c55",
   "metadata": {},
   "source": [
    "# 1.2 Fingerprint hashing\n",
    "\n",
    "Using the previously selected data with the features you found pertinent, you have to:\n",
    "\n",
    "Implement your minhash function from scratch. No ready-made hash functions are allowed. Read the class material and search the internet if you need to. For reference, it may be practical to look at the description of hash functions in the book.\n",
    "\n",
    "Process the dataset and add each record to the MinHash. The subtask's goal is to try and map each consumer to its bin; to ensure this works well, be sure you understand how MinHash works and choose a matching threshold to use. Before moving on, experiment with different thresholds, explaining your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e649f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm as tq\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "172d4498",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/data.csv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4127f3",
   "metadata": {},
   "source": [
    "### SAVE GENDER AS STRING IN PART 1 INSTEAD OF CONVERTING IT HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01e59378",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.CustGender = df.CustGender.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1dae9645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>CustGender</th>\n",
       "      <th>CustomerClassAge</th>\n",
       "      <th>Richness</th>\n",
       "      <th>Expenditure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>T1</td>\n",
       "      <td>0</td>\n",
       "      <td>age_1</td>\n",
       "      <td>richness_6</td>\n",
       "      <td>exp_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>T2</td>\n",
       "      <td>1</td>\n",
       "      <td>age_4</td>\n",
       "      <td>richness_2</td>\n",
       "      <td>exp_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>T3</td>\n",
       "      <td>0</td>\n",
       "      <td>age_1</td>\n",
       "      <td>richness_6</td>\n",
       "      <td>exp_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>T4</td>\n",
       "      <td>0</td>\n",
       "      <td>age_3</td>\n",
       "      <td>richness_10</td>\n",
       "      <td>exp_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>T5</td>\n",
       "      <td>0</td>\n",
       "      <td>age_2</td>\n",
       "      <td>richness_4</td>\n",
       "      <td>exp_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041139</th>\n",
       "      <td>1041139</td>\n",
       "      <td>T1048563</td>\n",
       "      <td>1</td>\n",
       "      <td>age_2</td>\n",
       "      <td>richness_4</td>\n",
       "      <td>exp_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041140</th>\n",
       "      <td>1041140</td>\n",
       "      <td>T1048564</td>\n",
       "      <td>1</td>\n",
       "      <td>age_1</td>\n",
       "      <td>richness_7</td>\n",
       "      <td>exp_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041141</th>\n",
       "      <td>1041141</td>\n",
       "      <td>T1048565</td>\n",
       "      <td>1</td>\n",
       "      <td>age_2</td>\n",
       "      <td>richness_10</td>\n",
       "      <td>exp_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041142</th>\n",
       "      <td>1041142</td>\n",
       "      <td>T1048566</td>\n",
       "      <td>1</td>\n",
       "      <td>age_3</td>\n",
       "      <td>richness_4</td>\n",
       "      <td>exp_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041143</th>\n",
       "      <td>1041143</td>\n",
       "      <td>T1048567</td>\n",
       "      <td>1</td>\n",
       "      <td>age_2</td>\n",
       "      <td>richness_8</td>\n",
       "      <td>exp_8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1041144 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0 TransactionID  CustGender CustomerClassAge     Richness  \\\n",
       "0                 0            T1           0            age_1   richness_6   \n",
       "1                 1            T2           1            age_4   richness_2   \n",
       "2                 2            T3           0            age_1   richness_6   \n",
       "3                 3            T4           0            age_3  richness_10   \n",
       "4                 4            T5           0            age_2   richness_4   \n",
       "...             ...           ...         ...              ...          ...   \n",
       "1041139     1041139      T1048563           1            age_2   richness_4   \n",
       "1041140     1041140      T1048564           1            age_1   richness_7   \n",
       "1041141     1041141      T1048565           1            age_2  richness_10   \n",
       "1041142     1041142      T1048566           1            age_3   richness_4   \n",
       "1041143     1041143      T1048567           1            age_2   richness_8   \n",
       "\n",
       "        Expenditure  \n",
       "0             exp_1  \n",
       "1            exp_10  \n",
       "2             exp_6  \n",
       "3             exp_9  \n",
       "4             exp_9  \n",
       "...             ...  \n",
       "1041139       exp_7  \n",
       "1041140       exp_6  \n",
       "1041141       exp_7  \n",
       "1041142       exp_7  \n",
       "1041143       exp_8  \n",
       "\n",
       "[1041144 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbec36df",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21aeca64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TransactionID', 'CustGender', 'CustomerClassAge', 'Richness', 'Expenditure']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc8bf41",
   "metadata": {},
   "source": [
    "# 1.2.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e580a",
   "metadata": {},
   "source": [
    "First of all we built the vocabulary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ec481bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab1 = ['0', '1'] #adding 0,1 shingles for female, male\n",
    "\n",
    "vocab2 = ['age_1', 'age_2', 'age_3', 'age_4', 'age_5', 'age_6']  #adding customerClassAge shingles without considering 0 class age (nan)\n",
    "\n",
    "vocab3 = ['richness_1', 'richness_2', 'richness_3', 'richness_4', 'richness_5', 'richness_6', 'richness_7', 'richness_8', 'richness_9', 'richness_10']\n",
    "\n",
    "#adding Richness shingles\n",
    "\n",
    "vocab4 = ['exp_1', 'exp_2', 'exp_3', 'exp_4', 'exp_5', 'exp_6', 'exp_7', 'exp_8', 'exp_9', 'exp_10']\n",
    "\n",
    "#adding Expenditure shingles\n",
    "\n",
    "vocabulary = vocab1 + vocab2 + vocab3 + vocab4\n",
    "vocabulary = np.array(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6200ea50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 'age_1', 'age_2', 'age_3', 'age_4', 'age_5', 'age_6', 'richness_1', 'richness_2', 'richness_3', 'richness_4', 'richness_5', 'richness_6', 'richness_7', 'richness_8', 'richness_9', 'richness_10', 'exp_1', 'exp_2', 'exp_3', 'exp_4', 'exp_5', 'exp_6', 'exp_7', 'exp_8', 'exp_9', 'exp_10']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95481264",
   "metadata": {},
   "source": [
    "We found different approaches to build the signature matrix and we decide to show all of them:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a97def",
   "metadata": {},
   "source": [
    "# First Approach: create one hot vector for each transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dae9e7b",
   "metadata": {},
   "source": [
    "First of all we created the function which maps each transaction into a vector of 0/1 based on the vocabulary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b838ed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 approach\n",
    "\n",
    "def hot_vector(data, index):  #create one hot vector with all the zeros and ones\n",
    "    \n",
    "    values = data.loc[index][['CustGender', 'CustomerClassAge', 'Richness', 'Expenditure']].values\n",
    "    indeces = np.where(values.reshape(values.size, 1) == vocabulary)[1]\n",
    "    vector = np.zeros(len(vocabulary))\n",
    "    vector[indeces] = 1\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c5c282",
   "metadata": {},
   "source": [
    "Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c41f5cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(hot_vector(df, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a3d5da",
   "metadata": {},
   "source": [
    "Now we can build a sparse matrix with all the encoded transiction: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77acd2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 1041144/1041144 [13:10<00:00, 1317.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Matrix shingles\n",
    "boolean_matrix = np.zeros((1041144, 28))\n",
    "\n",
    "for i in tq(range(len(df))):\n",
    "    # Append the one hot vectors as rows, we need to transpose later\n",
    "    boolean_matrix[df.index[i]] = hot_vector(df, i) \n",
    "    \n",
    "#boolean_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7c0c082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'boolean_matrix' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store boolean_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30ad0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "shingle_matrix_copy = np.copy(boolean_matrix).T\n",
    "\n",
    "#np.random.shuffle(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "58ffdd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 1041144)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shingle_matrix_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7d41d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_vector(df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f66c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. shuffle the matrix\n",
    "np.random.shuffle(shingle_matrix_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "11d40774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 13,  6, ...,  9,  2,  3], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. for each column, find the row where the first one appears\n",
    "np.argmax(shingle_matrix_copy == 1, axis=0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d43caa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_permutations = 12\n",
    "signature_matrix = np.zeros((12, shingle_matrix_copy.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2e25cf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:12<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tq(range(n_permutations)):\n",
    "    np.random.shuffle(shingle_matrix_copy)\n",
    "    signature_row = np.argmax(shingle_matrix_copy == 1, axis=0) + 1\n",
    "    \n",
    "    signature_matrix[i] = signature_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "617f0bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  4.,  2., ...,  7.,  7.,  7.],\n",
       "       [ 2., 15.,  2., ...,  5., 15.,  5.],\n",
       "       [ 3.,  4., 11., ...,  5., 10.,  7.],\n",
       "       ...,\n",
       "       [ 1.,  2.,  1., ...,  7.,  5., 13.],\n",
       "       [ 7.,  6., 10., ...,  2.,  6.,  2.],\n",
       "       [15.,  3., 15., ...,  2.,  2.,  6.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3ea0bf",
   "metadata": {},
   "source": [
    "With this matrix we can built the signature matrix simply taking the first occurrence of 1 in each column and shuffling the shingles for each row. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e9e2a6",
   "metadata": {},
   "source": [
    "# Second approach: build the boolean matrix storing the index of the ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b7abe1",
   "metadata": {},
   "source": [
    "Instead of storing all the zeros we defined a function that encodes the one hot vector in a list that contains the indexes of the 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57ca5565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#version 1\n",
    "\n",
    "def position_1(data, index): #take as input the dataframe and the index of the row\n",
    "    \n",
    "    ind = [] #initialize the list that will contain the indexes\n",
    "    \n",
    "    for (i,elem) in enumerate(vocabulary): \n",
    "        \n",
    "        #iterate over the element of the vocabulary and if a match is found append the index i to the list\n",
    "        \n",
    "        if elem in list(data.loc[index][['CustGender', 'CustomerClassAge', 'Richness', 'Expenditure']]): \n",
    "            \n",
    "            ind.append(i)\n",
    "    \n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4bde10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#version 2: same idea with the list comprehension --> more compact way\n",
    "\n",
    "def position_2(data, index):\n",
    "    \n",
    "    ind = [i for i, elem in enumerate(vocabulary) if elem in list(data.loc[index][['CustGender', 'CustomerClassAge', 'Richness', 'Expenditure']])]\n",
    "    \n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75175232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(hot_vector(df, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79c22e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 9, 27]\n"
     ]
    }
   ],
   "source": [
    "print(position_2(df, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad704854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 9, 27]\n"
     ]
    }
   ],
   "source": [
    "print(position_1(df, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c207e4b5",
   "metadata": {},
   "source": [
    "Now we can map the dataframe into a dictionary: the keys are the transaction ID and the values ar list of indexes where 1 appears:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bc8d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_matrix = dict() #initialize the dict\n",
    "\n",
    "for i in tq(range(len(df))):  #iterate over the dataframe\n",
    "    \n",
    "    boolean_matrix[df.loc[i][0]] = position_2(df, i)  #append keys: transaction id, value: list of indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f4a776",
   "metadata": {},
   "source": [
    "# Third approach: build directly the signature matrix: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84173c87",
   "metadata": {},
   "source": [
    "The goal of the MinHash is to replace a large set with a smaller \"signature\" that still preserves the underlying similarity metric. In order to create a MinHash signature for each set:\n",
    "\n",
    " - Randomly permute the rows of the shingle matrix (permuting the indexes)\n",
    " \n",
    " - For each set, start from the first index and find the position of the first shingle with a 1 in its cell. Use this shingle number to represent the set. This is the \"signature\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d709da",
   "metadata": {},
   "source": [
    "The idea started from shuffling the vocabulary instead of the rows of the boolean matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "304b601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as ran #shuffle the elements of a list\n",
    "ran.seed(7) #set seed for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182ccc9a",
   "metadata": {},
   "source": [
    "How does it work: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9794b387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' 'age_1' 'age_2' 'age_3' 'age_4' 'age_5' 'age_6' 'richness_1'\n",
      " 'richness_2' 'richness_3' 'richness_4' 'richness_5' 'richness_6'\n",
      " 'richness_7' 'richness_8' 'richness_9' 'richness_10' 'exp_1' 'exp_2'\n",
      " 'exp_3' 'exp_4' 'exp_5' 'exp_6' 'exp_7' 'exp_8' 'exp_9' 'exp_10']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80204f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran.shuffle(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e22162f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['richness_2' 'age_4' 'exp_5' 'richness_1' 'age_6' 'exp_9' 'richness_7'\n",
      " 'exp_2' 'exp_10' 'exp_7' 'richness_6' 'exp_8' 'richness_8' 'exp_4' '0'\n",
      " 'age_5' 'richness_9' 'exp_6' 'exp_1' 'richness_4' 'age_2' 'richness_10'\n",
      " 'age_1' '1' 'exp_3' 'richness_5' 'age_3' 'richness_3']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb290a99",
   "metadata": {},
   "source": [
    "The logic is similar to the previous points but the idea is the following: iterate over the vocabulary and return the position of the occurrence of the first 1, i.e. the first match with the current position of the elements in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffefe44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_shuffle(data, index): #take as input the dataframe and the index of the row\n",
    "    \n",
    "    for (i, elem) in enumerate(vocabulary): #iterate over the vocabulary\n",
    "        \n",
    "        #search for a match\n",
    "        if elem in list(data.loc[index][['CustGender', 'CustomerClassAge', 'Richness', 'Expenditure']]):\n",
    "        \n",
    "            return i  #return the index of the first match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9a2e3a",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1179377c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustGender                   1\n",
       "CustomerClassAge         age_4\n",
       "Richness            richness_2\n",
       "Expenditure             exp_10\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1][['CustGender', 'CustomerClassAge', 'Richness', 'Expenditure']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ab1003a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['richness_2', 'age_4', 'exp_5', 'richness_1', 'age_6', 'exp_9', 'richness_7', 'exp_2', 'exp_10', 'exp_7', 'richness_6', 'exp_8', 'richness_8', 'exp_4', 0, 'age_5', 'richness_9', 'exp_6', 'exp_1', 'richness_4', 'age_2', 'richness_10', 'age_1', 1, 'exp_3', 'richness_5', 'age_3', 'richness_3']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e48bb0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_shuffle(df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5146025",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran.shuffle(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e744b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['richness_5' '0' 'exp_8' '1' 'richness_7' 'richness_10' 'richness_2'\n",
      " 'exp_9' 'richness_9' 'age_5' 'age_1' 'exp_5' 'richness_6' 'age_3'\n",
      " 'exp_10' 'richness_4' 'richness_1' 'age_2' 'exp_4' 'exp_7' 'age_6'\n",
      " 'exp_6' 'exp_3' 'exp_2' 'age_4' 'richness_8' 'richness_3' 'exp_1']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41fb00fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_shuffle(df, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0865024",
   "metadata": {},
   "source": [
    "We created a list of the transactionID to initialize the column names of the signature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d50ee938",
   "metadata": {},
   "outputs": [],
   "source": [
    "TID = list(df['TransactionID']) #transaction names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eff3c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_matrix = pd.DataFrame(columns = TID) #initialize dataframe with transactionID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d967a2d",
   "metadata": {},
   "source": [
    "Choosing 10 as the number of permutation, we iterate shuffling the vocabulary at each step and appending "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1c2db26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/12 [00:00<?, ?it/s]\n",
      "  0%|                                                                                      | 0/1041144 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                                          | 21/1041144 [00:00<1:30:43, 191.24it/s]\u001b[A\n",
      "  0%|                                                                          | 50/1041144 [00:00<1:11:09, 243.83it/s]\u001b[A\n",
      "  0%|                                                                          | 87/1041144 [00:00<1:01:12, 283.47it/s]\u001b[A\n",
      "  0%|                                                                         | 117/1041144 [00:00<1:00:14, 288.00it/s]\u001b[A\n",
      "  0%|                                                                         | 146/1041144 [00:00<1:00:09, 288.41it/s]\u001b[A\n",
      "  0%|                                                                         | 177/1041144 [00:00<1:01:07, 283.82it/s]\u001b[A\n",
      "  0%|                                                                         | 206/1041144 [00:00<1:00:45, 285.51it/s]\u001b[A\n",
      "  0%|                                                                         | 235/1041144 [00:00<1:12:58, 237.75it/s]\u001b[A\n",
      "  0%|                                                                         | 261/1041144 [00:01<1:18:59, 219.62it/s]\u001b[A\n",
      "  0%|                                                                         | 289/1041144 [00:01<1:14:20, 233.37it/s]\u001b[A\n",
      "  0%|                                                                         | 314/1041144 [00:01<1:14:30, 232.84it/s]\u001b[A\n",
      "  0%|                                                                         | 342/1041144 [00:01<1:13:22, 236.43it/s]\u001b[A\n",
      "  0%|                                                                         | 371/1041144 [00:01<1:09:17, 250.36it/s]\u001b[A\n",
      "  0%|                                                                         | 397/1041144 [00:01<1:09:16, 250.41it/s]\u001b[A\n",
      "  0%|                                                                         | 430/1041144 [00:01<1:05:50, 263.43it/s]\u001b[A\n",
      "  0%|                                                                         | 467/1041144 [00:01<1:01:08, 283.65it/s]\u001b[A\n",
      "  0%|                                                                         | 497/1041144 [00:01<1:01:04, 283.97it/s]\u001b[A\n",
      "  0%|                                                                         | 526/1041144 [00:02<1:09:57, 247.92it/s]\u001b[A\n",
      "  0%|                                                                         | 552/1041144 [00:02<1:20:30, 215.42it/s]\u001b[A\n",
      "  0%|                                                                         | 576/1041144 [00:02<1:19:29, 218.15it/s]\u001b[A\n",
      "  0%|                                                                         | 599/1041144 [00:02<1:22:11, 211.00it/s]\u001b[A\n",
      "  0%|                                                                         | 623/1041144 [00:02<1:19:35, 217.89it/s]\u001b[A\n",
      "  0%|                                                                         | 646/1041144 [00:02<1:22:24, 210.42it/s]\u001b[A\n",
      "  0%|                                                                         | 670/1041144 [00:02<1:19:36, 217.84it/s]\u001b[A\n",
      "  0%|                                                                         | 696/1041144 [00:02<1:15:50, 228.64it/s]\u001b[A\n",
      "  0%|                                                                         | 722/1041144 [00:02<1:13:12, 236.88it/s]\u001b[A\n",
      "  0%|                                                                         | 746/1041144 [00:03<1:18:20, 221.32it/s]\u001b[A\n",
      "  0%|                                                                         | 769/1041144 [00:03<1:18:37, 220.53it/s]\u001b[A\n",
      "  0%|                                                                         | 792/1041144 [00:03<1:18:44, 220.20it/s]\u001b[A\n",
      "  0%|                                                                         | 821/1041144 [00:03<1:14:44, 231.97it/s]\u001b[A\n",
      "  0%|                                                                         | 850/1041144 [00:03<1:09:57, 247.87it/s]\u001b[A\n",
      "  0%|                                                                         | 879/1041144 [00:03<1:06:44, 259.75it/s]\u001b[A\n",
      "  0%|                                                                         | 916/1041144 [00:03<1:01:57, 279.86it/s]\u001b[A\n",
      "  0%|                                                                         | 945/1041144 [00:03<1:01:28, 281.98it/s]\u001b[A\n",
      "  0%|                                                                           | 982/1041144 [00:03<58:54, 294.27it/s]\u001b[A\n",
      "  0%|                                                                          | 1012/1041144 [00:04<58:44, 295.10it/s]\u001b[A\n",
      "  0%|                                                                          | 1042/1041144 [00:04<58:36, 295.74it/s]\u001b[A\n",
      "  0%|                                                                        | 1072/1041144 [00:04<1:01:12, 283.21it/s]\u001b[A\n",
      "  0%|                                                                          | 1110/1041144 [00:04<58:03, 298.54it/s]\u001b[A\n",
      "  0%|                                                                        | 1140/1041144 [00:04<1:10:08, 247.10it/s]\u001b[A\n",
      "  0%|                                                                        | 1167/1041144 [00:04<1:09:14, 250.31it/s]\u001b[A\n",
      "  0%|                                                                        | 1194/1041144 [00:04<1:09:02, 251.03it/s]\u001b[A\n",
      "  0%|                                                                        | 1220/1041144 [00:04<1:11:21, 242.87it/s]\u001b[A\n",
      "  0%|                                                                        | 1245/1041144 [00:05<1:15:55, 228.28it/s]\u001b[A\n",
      "  0%|                                                                        | 1269/1041144 [00:05<1:18:43, 220.16it/s]\u001b[A\n",
      "  0%|                                                                        | 1293/1041144 [00:05<1:17:53, 222.48it/s]\u001b[A\n",
      "  0%|                                                                        | 1320/1041144 [00:05<1:16:41, 225.95it/s]\u001b[A\n",
      "  0%|                                                                        | 1355/1041144 [00:05<1:09:27, 249.53it/s]\u001b[A\n",
      "  0%|                                                                        | 1384/1041144 [00:05<1:09:18, 250.01it/s]\u001b[A\n",
      "  0%|                                                                        | 1412/1041144 [00:05<1:07:25, 256.98it/s]\u001b[A\n",
      "  0%|                                                                        | 1446/1041144 [00:05<1:04:24, 269.05it/s]\u001b[A\n",
      "  0%|                                                                        | 1475/1041144 [00:05<1:04:13, 269.83it/s]\u001b[A\n",
      "  0%|                                                                        | 1503/1041144 [00:06<1:10:49, 244.66it/s]\u001b[A\n",
      "  0%|                                                                        | 1528/1041144 [00:06<1:12:23, 239.37it/s]\u001b[A\n",
      "  0%|                                                                        | 1558/1041144 [00:06<1:07:58, 254.91it/s]\u001b[A\n",
      "  0%|                                                                        | 1586/1041144 [00:06<1:06:54, 258.98it/s]\u001b[A\n",
      "  0%|                                                                        | 1613/1041144 [00:06<1:12:58, 237.41it/s]\u001b[A\n",
      "  0%|                                                                        | 1638/1041144 [00:06<1:12:10, 240.06it/s]\u001b[A\n",
      "  0%|                                                                        | 1663/1041144 [00:06<1:11:43, 241.56it/s]\u001b[A\n",
      "  0%|                                                                        | 1688/1041144 [00:06<1:16:13, 227.27it/s]\u001b[A\n",
      "  0%|                                                                        | 1712/1041144 [00:06<1:24:41, 204.56it/s]\u001b[A\n",
      "  0%|                                                                        | 1734/1041144 [00:07<1:23:55, 206.40it/s]\u001b[A\n",
      "  0%|                                                                        | 1757/1041144 [00:07<1:22:20, 210.39it/s]\u001b[A\n",
      "  0%|                                                                        | 1783/1041144 [00:07<1:17:22, 223.90it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                       | 1820/1041144 [00:07<1:07:56, 254.98it/s]\u001b[A\n",
      "  0%|▏                                                                       | 1846/1041144 [00:07<1:17:21, 223.93it/s]\u001b[A\n",
      "  0%|▏                                                                       | 1870/1041144 [00:07<1:18:52, 219.58it/s]\u001b[A\n",
      "  0%|▏                                                                       | 1894/1041144 [00:07<1:17:00, 224.93it/s]\u001b[A\n",
      "  0%|▏                                                                       | 1922/1041144 [00:07<1:12:24, 239.23it/s]\u001b[A\n",
      "  0%|▏                                                                       | 1947/1041144 [00:08<1:19:20, 218.31it/s]\u001b[A\n",
      "  0%|▏                                                                       | 1970/1041144 [00:08<1:23:11, 208.18it/s]\u001b[A\n",
      "  0%|▏                                                                       | 1992/1041144 [00:08<1:46:14, 163.02it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2010/1041144 [00:08<1:48:49, 159.14it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2028/1041144 [00:08<1:49:38, 157.97it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2045/1041144 [00:08<1:47:52, 160.54it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2067/1041144 [00:08<1:38:29, 175.84it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2089/1041144 [00:08<1:32:25, 187.37it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2109/1041144 [00:09<1:38:01, 176.67it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2140/1041144 [00:09<1:22:33, 209.75it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2170/1041144 [00:09<1:16:47, 225.49it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2193/1041144 [00:09<1:19:41, 217.28it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2216/1041144 [00:09<1:22:33, 209.74it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2238/1041144 [00:09<1:24:31, 204.86it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2267/1041144 [00:09<1:16:17, 226.95it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2296/1041144 [00:09<1:10:54, 244.17it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2330/1041144 [00:09<1:06:23, 260.78it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2357/1041144 [00:09<1:05:54, 262.69it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2395/1041144 [00:10<1:01:02, 283.60it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2424/1041144 [00:10<1:00:49, 284.65it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2457/1041144 [00:10<1:00:44, 284.99it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2486/1041144 [00:10<1:00:54, 284.24it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2515/1041144 [00:10<1:00:42, 285.13it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2544/1041144 [00:10<1:01:43, 280.46it/s]\u001b[A\n",
      "  0%|▏                                                                         | 2576/1041144 [00:10<59:54, 288.90it/s]\u001b[A\n",
      "  0%|▏                                                                         | 2612/1041144 [00:10<56:38, 305.60it/s]\u001b[A\n",
      "  0%|▏                                                                         | 2645/1041144 [00:10<57:32, 300.76it/s]\u001b[A\n",
      "  0%|▏                                                                         | 2676/1041144 [00:11<58:25, 296.27it/s]\u001b[A\n",
      "  0%|▏                                                                         | 2712/1041144 [00:11<56:43, 305.10it/s]\u001b[A\n",
      "  0%|▏                                                                         | 2743/1041144 [00:11<59:38, 290.20it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2773/1041144 [00:11<1:02:55, 275.00it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2802/1041144 [00:11<1:02:20, 277.59it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2830/1041144 [00:11<1:04:56, 266.44it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2857/1041144 [00:11<1:17:31, 223.20it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2884/1041144 [00:11<1:14:08, 233.37it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2920/1041144 [00:12<1:06:47, 259.07it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2947/1041144 [00:12<1:06:13, 261.30it/s]\u001b[A\n",
      "  0%|▏                                                                       | 2974/1041144 [00:12<1:08:34, 252.34it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3004/1041144 [00:12<1:05:46, 263.04it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3038/1041144 [00:12<1:02:55, 274.97it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3066/1041144 [00:12<1:02:45, 275.69it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3094/1041144 [00:12<1:04:36, 267.79it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3121/1041144 [00:12<1:12:04, 240.05it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3146/1041144 [00:12<1:19:57, 216.35it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3169/1041144 [00:13<1:24:39, 204.34it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3190/1041144 [00:13<1:25:58, 201.22it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3216/1041144 [00:13<1:20:27, 215.02it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3244/1041144 [00:13<1:14:57, 230.75it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3275/1041144 [00:13<1:08:37, 252.07it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3307/1041144 [00:13<1:04:38, 267.56it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3340/1041144 [00:13<1:04:00, 270.22it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3372/1041144 [00:13<1:02:55, 274.87it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3400/1041144 [00:13<1:05:21, 264.65it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3427/1041144 [00:14<1:08:41, 251.78it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3467/1041144 [00:14<1:01:36, 280.75it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3496/1041144 [00:14<1:01:04, 283.17it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3527/1041144 [00:14<1:00:11, 287.29it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3556/1041144 [00:14<1:03:05, 274.10it/s]\u001b[A\n",
      "  0%|▏                                                                       | 3584/1041144 [00:14<1:03:35, 271.97it/s]\u001b[A\n",
      "  0%|▎                                                                       | 3616/1041144 [00:14<1:01:02, 283.31it/s]\u001b[A\n",
      "  0%|▎                                                                       | 3655/1041144 [00:14<1:10:27, 245.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/12 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [28], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m     rows \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;66;03m#initialize the row\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m tq(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(TID))): \n\u001b[1;32m----> 9\u001b[0m         rows[TID[j]] \u001b[38;5;241m=\u001b[39m \u001b[43mposition_shuffle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#key: transactionID, value: number of the firs occurrence of a 1\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     signature_matrix \u001b[38;5;241m=\u001b[39m signature_matrix\u001b[38;5;241m.\u001b[39mappend(rows, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#append rows to signature matrix\u001b[39;00m\n\u001b[0;32m     13\u001b[0m signature_matrix\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/giacomo/Desktop/locale/signature_matrix.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [16], line 6\u001b[0m, in \u001b[0;36mposition_shuffle\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mposition_shuffle\u001b[39m(data, index): \u001b[38;5;66;03m#take as input the dataframe and the index of the row\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (i, elem) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(vocabulary): \u001b[38;5;66;03m#iterate over the vocabulary\u001b[39;00m\n\u001b[0;32m      4\u001b[0m         \n\u001b[0;32m      5\u001b[0m         \u001b[38;5;66;03m#search for a match\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustGender\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustomerClassAge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRichness\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExpenditure\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m):\n\u001b[0;32m      8\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m i\n",
      "File \u001b[1;32mc:\\users\\jonas\\desktop\\uni\\msc\\year 1\\adm\\homework_4\\adm_hw4\\venv\\lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m   1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_values(key)\n\u001b[1;32m-> 1007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\jonas\\desktop\\uni\\msc\\year 1\\adm\\homework_4\\adm_hw4\\venv\\lib\\site-packages\\pandas\\core\\series.py:1047\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[key]\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;66;03m# handle the dup indexing case GH#4246\u001b[39;00m\n\u001b[1;32m-> 1047\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\jonas\\desktop\\uni\\msc\\year 1\\adm\\homework_4\\adm_hw4\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1070\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1072\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\jonas\\desktop\\uni\\msc\\year 1\\adm\\homework_4\\adm_hw4\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1301\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1299\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\users\\jonas\\desktop\\uni\\msc\\year 1\\adm\\homework_4\\adm_hw4\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1239\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1238\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1239\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1241\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m )\n",
      "File \u001b[1;32mc:\\users\\jonas\\desktop\\uni\\msc\\year 1\\adm\\homework_4\\adm_hw4\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1429\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1430\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1432\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\users\\jonas\\desktop\\uni\\msc\\year 1\\adm\\homework_4\\adm_hw4\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6108\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6105\u001b[0m     keyarr \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(keyarr)\n\u001b[0;32m   6107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 6108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6109\u001b[0m     keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex(keyarr)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   6110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\users\\jonas\\desktop\\uni\\msc\\year 1\\adm\\homework_4\\adm_hw4\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6095\u001b[0m, in \u001b[0;36mIndex.get_indexer_for\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   6077\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6078\u001b[0m \u001b[38;5;124;03mGuaranteed return of an indexer even when non-unique.\u001b[39;00m\n\u001b[0;32m   6079\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6092\u001b[0m \u001b[38;5;124;03marray([0, 2])\u001b[39;00m\n\u001b[0;32m   6093\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 6095\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6096\u001b[0m indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n\u001b[0;32m   6097\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indexer\n",
      "File \u001b[1;32mc:\\users\\jonas\\desktop\\uni\\msc\\year 1\\adm\\homework_4\\adm_hw4\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3900\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3898\u001b[0m method \u001b[38;5;241m=\u001b[39m missing\u001b[38;5;241m.\u001b[39mclean_reindex_fill_method(method)\n\u001b[0;32m   3899\u001b[0m orig_target \u001b[38;5;241m=\u001b[39m target\n\u001b[1;32m-> 3900\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_cast_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3902\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n",
      "File \u001b[1;32mc:\\users\\jonas\\desktop\\uni\\msc\\year 1\\adm\\homework_4\\adm_hw4\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6623\u001b[0m, in \u001b[0;36mIndex._maybe_cast_listlike_indexer\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   6619\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_cast_listlike_indexer\u001b[39m(\u001b[38;5;28mself\u001b[39m, target) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m   6620\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6621\u001b[0m \u001b[38;5;124;03m    Analogue to maybe_cast_indexer for get_indexer instead of get_loc.\u001b[39;00m\n\u001b[0;32m   6622\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mensure_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\jonas\\desktop\\uni\\msc\\year 1\\adm\\homework_4\\adm_hw4\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:7376\u001b[0m, in \u001b[0;36mensure_index\u001b[1;34m(index_like, copy)\u001b[0m\n\u001b[0;32m   7374\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Index\u001b[38;5;241m.\u001b[39m_with_infer(index_like, copy\u001b[38;5;241m=\u001b[39mcopy, tupleize_cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   7375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 7376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\jonas\\desktop\\uni\\msc\\year 1\\adm\\homework_4\\adm_hw4\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:717\u001b[0m, in \u001b[0;36mIndex._with_infer\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    716\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*the Index constructor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 717\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m _dtype_obj \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_is_multi:\n\u001b[0;32m    720\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"maybe_convert_objects\" has incompatible type\u001b[39;00m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;66;03m# \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m    723\u001b[0m     values \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result\u001b[38;5;241m.\u001b[39m_values)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\jonas\\desktop\\uni\\msc\\year 1\\adm\\homework_4\\adm_hw4\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:543\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[1;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m     arr \u001b[38;5;241m=\u001b[39m klass\u001b[38;5;241m.\u001b[39m_ensure_array(arr, dtype, copy)\n\u001b[0;32m    542\u001b[0m     disallow_kwargs(kwargs)\n\u001b[1;32m--> 543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_simple_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_scalar(data):\n\u001b[0;32m    546\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_scalar_data_error(data)\n",
      "File \u001b[1;32mc:\\users\\jonas\\desktop\\uni\\msc\\year 1\\adm\\homework_4\\adm_hw4\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:691\u001b[0m, in \u001b[0;36mIndex._simple_new\u001b[1;34m(cls, values, name)\u001b[0m\n\u001b[0;32m    684\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex.asi8 is deprecated and will be removed in a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    686\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    687\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    688\u001b[0m     )\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 691\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_simple_new\u001b[39m(\u001b[38;5;28mcls\u001b[39m: \u001b[38;5;28mtype\u001b[39m[_IndexT], values, name: Hashable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _IndexT:\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;124;03m    We require that we have a dtype compat for the values. If we are passed\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;124;03m    a non-dtype compat, then coerce using the constructor.\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \n\u001b[0;32m    697\u001b[0m \u001b[38;5;124;03m    Must be careful not to recurse.\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_data_cls), \u001b[38;5;28mtype\u001b[39m(values)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tq(range(12)): #number of permutation\n",
    "    \n",
    "    ran.shuffle(vocabulary) #shuffle the vocabulary\n",
    "    \n",
    "    rows = {} #initialize the row\n",
    "    \n",
    "    for j in range(len(TID)): \n",
    "        \n",
    "        rows[TID[j]] = position_shuffle(df, j)  #key: transactionID, value: number of the firs occurrence of a 1\n",
    "        \n",
    "    signature_matrix = signature_matrix.append(rows, ignore_index=True) #append rows to signature matrix\n",
    "    \n",
    "signature_matrix.to_csv('/Users/giacomo/Desktop/locale/signature_matrix.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9ebe27d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>T11</th>\n",
       "      <th>...</th>\n",
       "      <th>T995</th>\n",
       "      <th>T996</th>\n",
       "      <th>T997</th>\n",
       "      <th>T998</th>\n",
       "      <th>T999</th>\n",
       "      <th>T1000</th>\n",
       "      <th>T1001</th>\n",
       "      <th>T1002</th>\n",
       "      <th>T1003</th>\n",
       "      <th>T1004</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 999 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   T2  T3  T4  T5  T6  T7  T8  T9 T10 T11  ... T995 T996 T997 T998 T999 T1000  \\\n",
       "0   3   6   3   3   0   3   3   0   0   0  ...    0    0    0    0   11     3   \n",
       "1  12   8   0  13   4   9   0   1   4   4  ...    4    4    4    4    2     5   \n",
       "2   3  11   0   4   4   1   0  10   1   2  ...   14    6   14   12    2     6   \n",
       "3   0   4   0   9  10   8  12   1   7   4  ...    4    2    2    9    4     2   \n",
       "4   9  11   3   5   5  14   3  12   0   2  ...    2    9    9    2    4     9   \n",
       "5   3   1   7   0   0   5   7   8   5  11  ...   11    3    3    2    7     3   \n",
       "6   2  16   2   2   2   0   2   8   0   9  ...   19    1   14    2    4     1   \n",
       "7   5   9  15   1   8   1  15   0   7   2  ...    8    5    5    6    2     5   \n",
       "8   2   0   2   3   3  10   2  11  10  13  ...    5    6    5   13    2     2   \n",
       "9   4   0   4   3   3   8  13   0   8   0  ...    0    0    0    5    0     6   \n",
       "\n",
       "  T1001 T1002 T1003 T1004  \n",
       "0     0    13     6     0  \n",
       "1     4     1     8     4  \n",
       "2    13     9    11     3  \n",
       "3     4     4     4     0  \n",
       "4    15    12     6     2  \n",
       "5     6     8     1    11  \n",
       "6    11     4     5    12  \n",
       "7     8     0     6     8  \n",
       "8     1    15     0    13  \n",
       "9     0     0     0     0  \n",
       "\n",
       "[10 rows x 999 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
