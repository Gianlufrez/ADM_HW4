{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e465c55",
   "metadata": {},
   "source": [
    "# 1.2 Fingerprint hashing\n",
    "\n",
    "Using the previously selected data with the features you found pertinent, you have to:\n",
    "\n",
    "Implement your minhash function from scratch. No ready-made hash functions are allowed. Read the class material and search the internet if you need to. For reference, it may be practical to look at the description of hash functions in the book.\n",
    "\n",
    "Process the dataset and add each record to the MinHash. The subtask's goal is to try and map each consumer to its bin; to ensure this works well, be sure you understand how MinHash works and choose a matching threshold to use. Before moving on, experiment with different thresholds, explaining your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e649f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm as tq\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "172d4498",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/giacomo/Desktop/locale/data.csv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81786c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>CustGender</th>\n",
       "      <th>CustomerClassAge</th>\n",
       "      <th>Richness</th>\n",
       "      <th>Expenditure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>T1</td>\n",
       "      <td>0</td>\n",
       "      <td>age_1</td>\n",
       "      <td>richness_6</td>\n",
       "      <td>exp_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>T2</td>\n",
       "      <td>1</td>\n",
       "      <td>age_4</td>\n",
       "      <td>richness_2</td>\n",
       "      <td>exp_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>T3</td>\n",
       "      <td>0</td>\n",
       "      <td>age_1</td>\n",
       "      <td>richness_6</td>\n",
       "      <td>exp_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>T4</td>\n",
       "      <td>0</td>\n",
       "      <td>age_3</td>\n",
       "      <td>richness_10</td>\n",
       "      <td>exp_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>T5</td>\n",
       "      <td>0</td>\n",
       "      <td>age_2</td>\n",
       "      <td>richness_4</td>\n",
       "      <td>exp_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041139</th>\n",
       "      <td>1041139</td>\n",
       "      <td>T1048563</td>\n",
       "      <td>1</td>\n",
       "      <td>age_2</td>\n",
       "      <td>richness_4</td>\n",
       "      <td>exp_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041140</th>\n",
       "      <td>1041140</td>\n",
       "      <td>T1048564</td>\n",
       "      <td>1</td>\n",
       "      <td>age_1</td>\n",
       "      <td>richness_7</td>\n",
       "      <td>exp_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041141</th>\n",
       "      <td>1041141</td>\n",
       "      <td>T1048565</td>\n",
       "      <td>1</td>\n",
       "      <td>age_2</td>\n",
       "      <td>richness_10</td>\n",
       "      <td>exp_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041142</th>\n",
       "      <td>1041142</td>\n",
       "      <td>T1048566</td>\n",
       "      <td>1</td>\n",
       "      <td>age_3</td>\n",
       "      <td>richness_4</td>\n",
       "      <td>exp_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041143</th>\n",
       "      <td>1041143</td>\n",
       "      <td>T1048567</td>\n",
       "      <td>1</td>\n",
       "      <td>age_2</td>\n",
       "      <td>richness_8</td>\n",
       "      <td>exp_8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1041144 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0 TransactionID  CustGender CustomerClassAge     Richness  \\\n",
       "0                 0            T1           0            age_1   richness_6   \n",
       "1                 1            T2           1            age_4   richness_2   \n",
       "2                 2            T3           0            age_1   richness_6   \n",
       "3                 3            T4           0            age_3  richness_10   \n",
       "4                 4            T5           0            age_2   richness_4   \n",
       "...             ...           ...         ...              ...          ...   \n",
       "1041139     1041139      T1048563           1            age_2   richness_4   \n",
       "1041140     1041140      T1048564           1            age_1   richness_7   \n",
       "1041141     1041141      T1048565           1            age_2  richness_10   \n",
       "1041142     1041142      T1048566           1            age_3   richness_4   \n",
       "1041143     1041143      T1048567           1            age_2   richness_8   \n",
       "\n",
       "        Expenditure  \n",
       "0             exp_1  \n",
       "1            exp_10  \n",
       "2             exp_6  \n",
       "3             exp_9  \n",
       "4             exp_9  \n",
       "...             ...  \n",
       "1041139       exp_7  \n",
       "1041140       exp_6  \n",
       "1041141       exp_7  \n",
       "1041142       exp_7  \n",
       "1041143       exp_8  \n",
       "\n",
       "[1041144 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbec36df",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21aeca64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TransactionID', 'CustGender', 'CustomerClassAge', 'Richness', 'Expenditure']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc8bf41",
   "metadata": {},
   "source": [
    "# 1.2.1 Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assumption: we used the dataset with the strings!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e580a",
   "metadata": {},
   "source": [
    "First of all we built the vocabulary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ec481bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab1 = [0, 1] #adding 0,1 shingles for female, male\n",
    "\n",
    "vocab2 = ['age_1', 'age_2', 'age_3', 'age_4', 'age_5', 'age_6']  #adding customerClassAge shingles without considering 0 class age (nan)\n",
    "\n",
    "vocab3 = ['richness_1', 'richness_2', 'richness_3', 'richness_4', 'richness_5', 'richness_6', 'richness_7', 'richness_8', 'richness_9', 'richness_10']\n",
    "\n",
    "#adding Richness shingles\n",
    "\n",
    "vocab4 = ['exp_1', 'exp_2', 'exp_3', 'exp_4', 'exp_5', 'exp_6', 'exp_7', 'exp_8', 'exp_9', 'exp_10']\n",
    "\n",
    "#adding Expenditure shingles\n",
    "\n",
    "vocabulary = vocab1 + vocab2 + vocab3 + vocab4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6200ea50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 'age_1', 'age_2', 'age_3', 'age_4', 'age_5', 'age_6', 'richness_1', 'richness_2', 'richness_3', 'richness_4', 'richness_5', 'richness_6', 'richness_7', 'richness_8', 'richness_9', 'richness_10', 'exp_1', 'exp_2', 'exp_3', 'exp_4', 'exp_5', 'exp_6', 'exp_7', 'exp_8', 'exp_9', 'exp_10']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a97def",
   "metadata": {},
   "source": [
    "# 1.2.2 Create one hot vector for each transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dae9e7b",
   "metadata": {},
   "source": [
    "First of all we created the function which maps each transaction into a vector of 0/1 based on the vocabulary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3c1c5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 'age_4', 'richness_2', 'exp_10']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.loc[1][['CustGender', 'CustomerClassAge', 'Richness', 'Expenditure']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34e909a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 approach\n",
    "\n",
    "def hot_vector(data, index):  #create one hot vector with all the zeros and ones\n",
    "    \n",
    "    vector = [1 if elem in list(data.loc[index][['CustGender', 'CustomerClassAge', 'Richness', 'Expenditure']]) else 0 for elem in vocabulary]\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd00b83d",
   "metadata": {},
   "source": [
    "Instead of storing all this zeros we defined a function that encodes the one hot vector in a list that contains the indexes of the 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35b08a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 approach first try\n",
    "\n",
    "def position_1(data, index):  #----> same time OF POSITION 2\n",
    "    \n",
    "    ind = []\n",
    "    \n",
    "    for (i,elem) in enumerate(vocabulary):\n",
    "        \n",
    "        if elem in list(data.loc[index][['CustGender', 'CustomerClassAge', 'Richness', 'Expenditure']]): \n",
    "            \n",
    "            ind.append(i)\n",
    "    \n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67ea8c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 try with list comprehension ---> same time\n",
    "\n",
    "def position_2(data, index):\n",
    "    \n",
    "    ind = [i for i, elem in enumerate(vocabulary) if elem in list(data.loc[index][['CustGender', 'CustomerClassAge', 'Richness', 'Expenditure']])]\n",
    "    \n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "569a22b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5, 9, 27]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_2(df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9553a96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5, 9, 27]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_1(df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aca314f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(hot_vector(df, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b809d1",
   "metadata": {},
   "source": [
    "# ALL THESE FUNCTION WORKED, BUT HOW TO TAKE LESS TIME WHEN I ITERATE ON THE INITIAL DATAFRAME? \n",
    "\n",
    "## Read after to understand what i mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3925af",
   "metadata": {},
   "source": [
    "# 1.2.3 Mapping each transaction through vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59226476",
   "metadata": {},
   "source": [
    "Now we can map the initial dataset to a dictionary/dataframe in which the keys are the Transaction ID and the values are the one hot vector:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f7e7f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. try  CORRECT BUT #too time\n",
    "\n",
    "boolean_matrix = pd.DataFrame(vocabulary, columns =['Shingles']) #initialize matrix shingles\n",
    "\n",
    "for i in tq(range(len(df))):\n",
    "    \n",
    "    boolean_matrix[df.loc[i][0]] = hot_vector(df, i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6a13f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. try CORRECT BUT TAKES TIME\n",
    "\n",
    "boolean_matrix = dict()\n",
    "\n",
    "for i in tq(range(len(df))):  #take 5/6 hours but it works\n",
    "    \n",
    "    boolean_matrix[df.loc[i][0]] = position_2(df, i) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde75653",
   "metadata": {},
   "source": [
    "# 1.2.4 Signature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bbc829",
   "metadata": {},
   "source": [
    "The goal of the MinHash is to replace a large set with a smaller \"signature\" that still preserves the underlying similarity metric. In order to create a MinHash signature for each set:\n",
    "\n",
    " - Randomly permute the rows of the shingle matrix (permuting the indexes)\n",
    " - For each set, start from the first index and find the position of the first shingle with a 1 in its cell. Use this shingle number to represent the set. This is the \"signature\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d6a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of permutation must be less that the number of shingles. \n",
    "#in fact we use signature matrix to reduce the size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16c52a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as ran #instead of shuffling the data set we shuffle the VOCABULARY\n",
    "\n",
    "ran.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "633bd942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age_5', 'exp_7', 'exp_9', 'exp_10', 'richness_1', 'age_1', 'exp_3', 'age_2', 'richness_3', 'exp_1', 'richness_10', 'exp_6', 1, 0, 'exp_8', 'richness_6', 'richness_9', 'richness_2', 'age_3', 'age_4', 'age_6', 'exp_5', 'exp_2', 'exp_4', 'richness_4', 'richness_8', 'richness_7', 'richness_5']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "426815fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran.shuffle(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bafcc824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['richness_8', 'exp_8', 'exp_6', 'exp_4', 'exp_3', 'exp_5', 'age_5', 'age_1', 'richness_9', 'richness_6', 'exp_2', 'exp_9', 'richness_10', 'richness_7', 'richness_3', 'age_4', 'exp_10', 'age_6', 0, 'exp_1', 'richness_1', 'richness_2', 'richness_4', 'age_2', 'exp_7', 1, 'richness_5', 'age_3']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2344c9",
   "metadata": {},
   "source": [
    "# Probably instead of do the mapping and after built the signature we can do everything togheter through an alternative version of the position function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0bbfa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes the position of the first one of a transaction in the \n",
    "#vocabulary matching!! ---> minash!\n",
    "\n",
    "def position_shuffle(data, index): #index is to choice the transaction to analyze\n",
    "    \n",
    "    for (i, elem) in enumerate(vocabulary):\n",
    "        \n",
    "        if elem in list(data.loc[index][['CustGender', 'CustomerClassAge', 'Richness', 'Expenditure']]):\n",
    "        \n",
    "            return i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a8738f",
   "metadata": {},
   "source": [
    "# Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a7d2d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustGender                   1\n",
       "CustomerClassAge         age_4\n",
       "Richness            richness_2\n",
       "Expenditure             exp_10\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1][['CustGender', 'CustomerClassAge', 'Richness', 'Expenditure']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b564290a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 'age_1', 'age_2', 'age_3', 'age_4', 'age_5', 'age_6', 'richness_1', 'richness_2', 'richness_3', 'richness_4', 'richness_5', 'richness_6', 'richness_7', 'richness_8', 'richness_9', 'richness_10', 'exp_1', 'exp_2', 'exp_3', 'exp_4', 'exp_5', 'exp_6', 'exp_7', 'exp_8', 'exp_9', 'exp_10']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32ffb733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_shuffle(df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a97b7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran.shuffle(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6e5a8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age_1', 'exp_3', 'age_5', 'age_2', 'exp_7', 0, 'exp_2', 'richness_5', 'exp_6', 'richness_9', 'exp_10', 'richness_1', 'age_3', 'exp_9', 1, 'exp_8', 'age_4', 'age_6', 'richness_2', 'richness_4', 'exp_5', 'exp_1', 'richness_7', 'richness_3', 'richness_6', 'richness_10', 'exp_4', 'richness_8']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9328ae3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_shuffle(df, 1)  #do the correct work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e2db2",
   "metadata": {},
   "source": [
    "# Below probably the shortest way and computational efficient to do all togheter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88551531",
   "metadata": {},
   "source": [
    "## In order to do that we have to build a signature matrix:\n",
    "\n",
    "- each element of th first row contains the first occurrence of 1 in encoded vector of the transaction\n",
    "\n",
    "- shuffle vocabulary --> second row\n",
    "\n",
    "- shuffle vocabulary --> third row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "030e0462",
   "metadata": {},
   "outputs": [],
   "source": [
    "TID = list(df['TransactionID']) #transaction names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8dd3577",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_matrix = pd.DataFrame(columns = TID) #initialize dataframe with transaction name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a689ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#for example we can take 10 number of permutation:\n",
    "\n",
    "for i in tq(range(10)): \n",
    "    \n",
    "    ran.shuffle(vocabulary) #shuffle the vocabulary\n",
    "    \n",
    "    rows = {} #create rows to append\n",
    "    \n",
    "    for j in range(len(TID)):\n",
    "        \n",
    "        rows[TID[j]] = position_shuffle(df, j)  #keys transactionid, value position of the first one\n",
    "        \n",
    "    df2 = df.append(rows, ignore_index=True) # append rows to signature matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38a9c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i think that order of complexity is much less than the previous all approach, \n",
    "\n",
    "#but it takes so much time also in this way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d9a67b",
   "metadata": {},
   "source": [
    "# 1.2.5 Bucket!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b675ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4ab1ed1",
   "metadata": {},
   "source": [
    "# 1.3 Query\n",
    "\n",
    "To execute the query we execute the same process of encoding and look in which bucket they go"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
